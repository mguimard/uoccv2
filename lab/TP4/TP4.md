# ğŸ› ï¸ Exercice : TolÃ©rance Ã  la panne dans un cluster Kubernetes

## ğŸ¯ Objectif

Comprendre et tester le comportement de Kubernetes en cas de panne dâ€™un nÅ“ud (`worker2`) en utilisant les objets **ReplicaSet** et **DaemonSet**.

## ğŸ§± Contexte

Vous disposez dâ€™un cluster Kubernetes composÃ© de 3 nÅ“uds :

- `master`
- `worker1`
- `worker2`

Vous allez :

1. DÃ©ployer un ReplicaSet avec plusieurs pods.
2. DÃ©ployer un DaemonSet avec un pod par nÅ“ud.
3. Simuler une panne de `worker2`.
4. Observer le comportement du cluster et la tolÃ©rance Ã  la panne.

---

## ğŸ§ª Ã‰tapes de l'exercice

### 1ï¸âƒ£ CrÃ©er un ReplicaSet

CrÃ©ez un fichier `replicaset.yaml` :

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-replicaset
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
````

Appliquez le manifeste :

```bash
kubectl apply -f replicaset.yaml
```

### 2ï¸âƒ£ CrÃ©er un DaemonSet

CrÃ©ez un fichier `daemonset.yaml` :

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: daemon-nginx
spec:
  selector:
    matchLabels:
      app: daemon-nginx
  template:
    metadata:
      labels:
        app: daemon-nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
```

Appliquez le manifeste :

```bash
kubectl apply -f daemonset.yaml
```

VÃ©rifiez la distribution des pods du DaemonSet :

```bash
kubectl get pods -o wide -l app=daemon-nginx
```

Vous devriez avoir un pod sur chaque nÅ“ud (`master`, `worker1`, `worker2`).

---

## ğŸ”¥ 3ï¸âƒ£ Simuler une panne du nÅ“ud `worker2`

Simulez une panne en arrÃªtant le service kubelet ou Ã©teignez le nÅ“ud dans votre environnement :

**Option A - Stopper kubelet sur le worker2:**

```bash
sudo systemctl stop kubelet
```

**Option B - Utiliser vagrant pour arreter la VM:**

```bash
# Sur la machine hÃ´te 
vagrant halt worker2
# Pour le redÃ©marrer plus tard
vagrant up worker2
```

Attendez quelques minutes (le dÃ©lai de dÃ©tection dÃ©pend du paramÃ©trage de lâ€™API server, gÃ©nÃ©ralement ~5 min).

---

## ğŸ“Š 4ï¸âƒ£ Observer le comportement du cluster

### ğŸ“Œ Questions Ã  rÃ©pondre :

1. Que devient le pod du DaemonSet prÃ©vu sur `worker2` ?
2. Que deviennent les pods du ReplicaSet initialement programmÃ©s sur `worker2` ?
3. Les pods sont-ils redÃ©ployÃ©s ailleurs ?
4. Combien de pods du ReplicaSet sont en Ã©tat `Running` aprÃ¨s la panne ?
5. Que se passe-t-il si vous relancez `worker2` ?

### ğŸ” Commandes utiles :

```bash
kubectl get nodes
kubectl describe nodes worker2
kubectl get pods -o wide
kubectl get rs
```
